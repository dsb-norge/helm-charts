Full manifest should match snapshot:
  1: |
    apiVersion: v1
    data:
      root.key1: value1
      root.key2: value2
    kind: ConfigMap
    metadata:
      name: RELEASE-NAME-configmap
      namespace: NAMESPACE
  2: |
    apiVersion: batch/v1
    kind: CronJob
    metadata:
      annotations:
        cronKey1: cronValue1
        cronKey2: cronValue2
        orgs.k8s.snyk.io/v1: 3c6b0e2e-36a2-4c0e-93c8-3ba8c87dd75d
      name: RELEASE-NAME-cron-cron-example
      namespace: NAMESPACE
    spec:
      concurrencyPolicy: Forbid
      failedJobsHistoryLimit: 3
      jobTemplate:
        metadata:
          annotations:
            co.elastic.logs/json.add_error_key: "true"
            co.elastic.logs/json.keys_under_root: "true"
            co.elastic.logs/json.overwrite_keys: "true"
        spec:
          activeDeadlineSeconds: 60
          backoffLimit: 3
          completions: 1
          parallelism: 1
          template:
            metadata:
              labels:
                app: RELEASE-NAME-cron
                cron: cron-example
            spec:
              containers:
              - env:
                - name: TOKEN_URL
                  value: https://example.com/token
                - name: CLIENT_ID
                  value: release-name-cron-client
                - name: API_METHOD
                  value: TRACE
                - name: API_PATH
                  value: http://RELEASE-NAME.NAMESPACE.svc.cluster.local:80/do
                envFrom:
                - secretRef:
                    name: jobSecret1
                image: dsbacr.azurecr.io/dsb-norge/oauth2-api-caller:greatest
                name: cron-example
                resources:
                  limits:
                    cpu: 50m
                    memory: 128Mi
                  requests:
                    cpu: 50m
                    memory: 64Mi
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
                  privileged: false
                  readOnlyRootFilesystem: true
                  runAsGroup: 3000
                  runAsNonRoot: true
                  runAsUser: 1000
              restartPolicy: OnFailure
      schedule: '*/2 * * * *'
      successfulJobsHistoryLimit: 2
  3: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: RELEASE-NAME-database-deployment
      namespace: NAMESPACE
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: RELEASE-NAME-db-app
      template:
        metadata:
          annotations:
            checksum: chart-version=3.0.19_config-hash=241d62a54c05cb987f57cbedee237584010c73d231f8622cee85637af173c119
          labels:
            app: RELEASE-NAME-db-app
        spec:
          containers:
          - env:
            - name: ACCEPT_EULA
              value: "Y"
            - name: SA_PASSWORD
              value: password123
            - name: MSSQL_SA_PASSWORD
              value: password123
            image: test-db:v1
            name: RELEASE-NAME-database-container
            ports:
            - containerPort: 1433
            resources:
              limits:
                cpu: "2.5"
                memory: 2048Mi
              requests:
                cpu: "0.2"
                memory: 1024Mi
          hostname: RELEASE-NAME-db-svc
  4: |
    apiVersion: v1
    kind: Service
    metadata:
      name: RELEASE-NAME-db-svc
      namespace: NAMESPACE
    spec:
      ports:
      - port: 1433
        protocol: TCP
        targetPort: 1433
      selector:
        app: RELEASE-NAME-db-app
  5: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      annotations:
        key1: value1
        key2: value2
        orgs.k8s.snyk.io/v1: 3c6b0e2e-36a2-4c0e-93c8-3ba8c87dd75d
      name: RELEASE-NAME-deployment
      namespace: NAMESPACE
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: RELEASE-NAME-app
      template:
        metadata:
          annotations:
            apparmor.security.beta.kubernetes.io/pod: runtime/default
            checksum: chart-version=3.0.19_config-hash=2250a820a0bdc4f1708b1a81c451b9a1084025a3b97e3ff2b9d17b8944f549e8
            co.elastic.logs/json.add_error_key: "true"
            co.elastic.logs/json.keys_under_root: "true"
            co.elastic.logs/json.overwrite_keys: "true"
          labels:
            app: RELEASE-NAME-app
            app.kubernetes.io/component: Backend API
            app.kubernetes.io/managed-by: Helm
            app.kubernetes.io/name: Rendering test
            app.kubernetes.io/part-of: Verification stuff
            app.kubernetes.io/version: greatest
        spec:
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - RELEASE-NAME-app
                topologyKey: kubernetes.io/hostname
          containers:
          - env:
            - name: SPRING_PROFILES_ACTIVE
              value: chart-testing
            - name: MANAGEMENT_METRICS_EXPORT_PROMETHEUS_ENABLED
              value: "true"
            - name: DATABASE_CONTAINER_USER
              value: custom user
            - name: DATABASE_CONTAINER_PASSWORD
              value: password123
            - name: DATABASE_CONTAINER_HOST_AND_PORT
              value: RELEASE-NAME-db-svc:1433
            - name: DATABASE_CONTAINER_DATABASE
              value: test-data
            - name: DSB_CERTIFICATE_CERTIFICATE_PATH
              value: /certificates/dsb-test-virksomhetssertifikat.pfx
            envFrom:
            - secretRef:
                name: secret1
            - secretRef:
                name: dsb-certificate-info
            - configMapRef:
                name: configMap1
            - configMapRef:
                name: RELEASE-NAME-configmap
            image: wordpress:greatest
            imagePullPolicy: customValue
            lifecycle:
              preStop:
                exec:
                  command:
                  - sh
                  - -c
                  - sleep 10
            livenessProbe:
              failureThreshold: 20
              httpGet:
                path: /actuator/health/liveness
                port: 81
              initialDelaySeconds: 15
              periodSeconds: 15
            name: RELEASE-NAME-container
            ports:
            - containerPort: 80
              name: web
            - containerPort: 81
              name: actuator
            readinessProbe:
              failureThreshold: 20
              httpGet:
                path: /actuator/health/readiness
                port: 81
              initialDelaySeconds: 10
              periodSeconds: 15
            resources:
              limits:
                cpu: 1
                memory: 19Mi
              requests:
                cpu: 0.3
                memory: 4Mi
            securityContext:
              allowPrivilegeEscalation: false
              capabilities:
                drop:
                - ALL
              privileged: false
              readOnlyRootFilesystem: true
              runAsGroup: 3000
              runAsNonRoot: true
              runAsUser: 1000
            volumeMounts:
            - mountPath: /tmp
              name: tmp-dir
            - mountPath: /certificates
              name: dsb-certificate
              readOnly: true
          nodeSelector:
            NodePool: workers
          serviceAccountName: RELEASE-NAME-service-account
          volumes:
          - emptyDir: {}
            name: tmp-dir
          - name: dsb-certificate
            secret:
              secretName: dsb-certificate-file
  6: |
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
      name: RELEASE-NAME
      namespace: NAMESPACE
    spec:
      rules:
      - host: example.com
        http:
          paths:
          - backend:
              service:
                name: RELEASE-NAME
                port:
                  number: 80
            path: /example
            pathType: Prefix
  7: |
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    metadata:
      name: RELEASE-NAME.pdb
    spec:
      minAvailable: 1
      selector:
        matchLabels:
          app: RELEASE-NAME-app
  8: |
    apiVersion: v1
    kind: Service
    metadata:
      labels:
        app: RELEASE-NAME-service
        app.kubernetes.io/component: Backend API
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: Rendering test
        app.kubernetes.io/part-of: Verification stuff
        app.kubernetes.io/version: greatest
        chart-name: dsb-spring-boot
        chart-version: 3.0.19
        management.port: "81"
        spring-boot: "true"
      name: RELEASE-NAME
      namespace: NAMESPACE
    spec:
      ports:
      - name: web
        port: 80
      - name: actuator
        port: 81
      selector:
        app: RELEASE-NAME-app
  9: |
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      labels:
        app: RELEASE-NAME-app
      name: RELEASE-NAME-service-account
      namespace: NAMESPACE
  10: |
    apiVersion: kubernetes-client.io/v1
    kind: ExternalSecret
    metadata:
      name: dsb-certificate-info
      namespace: NAMESPACE
    spec:
      backendType: azureKeyVault
      data:
      - key: value_for_password
        name: DSB_CERTIFICATE_CERTIFICATE_KEYSTORE
      - key: value_for_alias
        name: DSB_CERTIFICATE_CERTIFICATE_ALIAS
      keyVaultName: azure_key_vault_name
  11: |
    apiVersion: kubernetes-client.io/v1
    kind: ExternalSecret
    metadata:
      name: dsb-certificate-file
      namespace: NAMESPACE
    spec:
      backendType: azureKeyVault
      data:
      - isBinary: true
        key: vaule_for_certificate
        name: dsb-test-virksomhetssertifikat.pfx
      keyVaultName: azure_key_vault_name
  12: |
    apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      labels:
        release: kube-prometheus
      name: RELEASE-NAME-monitor
      namespace: NAMESPACE
    spec:
      endpoints:
      - path: /path/to/prometheus
        port: actuator
        scheme: http
      namespaceSelector:
        matchNames:
        - NAMESPACE
      selector:
        matchLabels:
          app: RELEASE-NAME-service
  13: |
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: RELEASE-NAME-cr
      namespace: NAMESPACE
    rules:
    - apiGroups:
      - ""
      resources:
      - nodes
      verbs:
      - list
      - get
    - apiGroups:
      - ""
      - apps
      resources:
      - pods
      - deployments
      verbs:
      - list
      - watch
      - get
  14: |
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: RELEASE-NAME-crb
      namespace: NAMESPACE
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: RELEASE-NAME-cr
    subjects:
    - kind: ServiceAccount
      name: RELEASE-NAME-service-account
      namespace: NAMESPACE
Minimal manifest should match snapshot:
  1: |
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      annotations:
        orgs.k8s.snyk.io/v1: 3c6b0e2e-36a2-4c0e-93c8-3ba8c87dd75d
      name: RELEASE-NAME-deployment
      namespace: NAMESPACE
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: RELEASE-NAME-app
      template:
        metadata:
          annotations:
            apparmor.security.beta.kubernetes.io/pod: runtime/default
            checksum: chart-version=3.0.19_config-hash=a3d953426134ec8a82f73f828b3fe9c1167f66062335868acf1421ffaa8f957d
            co.elastic.logs/json.add_error_key: "true"
            co.elastic.logs/json.keys_under_root: "true"
            co.elastic.logs/json.overwrite_keys: "true"
          labels:
            app: RELEASE-NAME-app
            app.kubernetes.io/component: API
            app.kubernetes.io/managed-by: Helm
            app.kubernetes.io/name: RELEASE-NAME
            app.kubernetes.io/part-of: RELEASE-NAME
            app.kubernetes.io/version: latest
        spec:
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                  - key: app
                    operator: In
                    values:
                    - RELEASE-NAME-app
                topologyKey: kubernetes.io/hostname
          containers:
          - env:
            - name: SPRING_PROFILES_ACTIVE
              value: kubernetes
            envFrom: null
            image: nginx:latest
            lifecycle:
              preStop:
                exec:
                  command:
                  - sh
                  - -c
                  - sleep 10
            livenessProbe:
              failureThreshold: 20
              httpGet:
                path: /actuator/health/liveness
                port: 8180
              initialDelaySeconds: 15
              periodSeconds: 15
            name: RELEASE-NAME-container
            ports:
            - containerPort: 8080
              name: web
            - containerPort: 8180
              name: actuator
            readinessProbe:
              failureThreshold: 20
              httpGet:
                path: /actuator/health/readiness
                port: 8180
              initialDelaySeconds: 10
              periodSeconds: 15
            resources:
              limits:
                cpu: 2.5
                memory: 1024Mi
              requests:
                cpu: 100m
                memory: 256Mi
            securityContext:
              allowPrivilegeEscalation: false
              capabilities:
                drop:
                - ALL
              privileged: false
              readOnlyRootFilesystem: true
              runAsGroup: 3000
              runAsNonRoot: true
              runAsUser: 1000
            volumeMounts:
            - mountPath: /tmp
              name: tmp-dir
          nodeSelector:
            NodePool: workers
          serviceAccountName: RELEASE-NAME-service-account
          volumes:
          - emptyDir: {}
            name: tmp-dir
  2: |
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    metadata:
      name: RELEASE-NAME.pdb
    spec:
      minAvailable: 1
      selector:
        matchLabels:
          app: RELEASE-NAME-app
  3: |
    apiVersion: v1
    kind: Service
    metadata:
      labels:
        app: RELEASE-NAME-service
        app.kubernetes.io/component: API
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: RELEASE-NAME
        app.kubernetes.io/part-of: RELEASE-NAME
        app.kubernetes.io/version: latest
        chart-name: dsb-spring-boot
        chart-version: 3.0.19
        management.port: "8180"
        spring-boot: "true"
      name: RELEASE-NAME
      namespace: NAMESPACE
    spec:
      ports:
      - name: web
        port: 8080
      - name: actuator
        port: 8180
      selector:
        app: RELEASE-NAME-app
  4: |
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      labels:
        app: RELEASE-NAME-app
      name: RELEASE-NAME-service-account
      namespace: NAMESPACE
should render default with PodDisruptionBudget and should match snapshot:
  1: |
    apiVersion: policy/v1
    kind: PodDisruptionBudget
    metadata:
      name: RELEASE-NAME.pdb
    spec:
      minAvailable: 1
      selector:
        matchLabels:
          app: RELEASE-NAME-app
